{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"private5위.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMmyjAzy2jIEmvi4pnHpiO+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01ors8wCuXj6","executionInfo":{"status":"ok","timestamp":1647585621206,"user_tz":-540,"elapsed":20076,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"e7ef4ffe-bd56-4433-b6aa-f2d615c1d41a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/hand_gesture_data/'"],"metadata":{"id":"WkNN_SY7uu5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","from scipy import stats\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import *\n","%matplotlib inline\n","\n","tf.random.set_seed(42) #재현을 위한 텐서플로우 seed 설정\n","\n","data_train = pd.read_csv(PATH+'train.csv')\n","data_test = pd.read_csv(PATH+'test.csv')\n","print(data_train.shape)\n","data_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"toVmNpYPu_9t","executionInfo":{"status":"ok","timestamp":1647585789167,"user_tz":-540,"elapsed":434,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"6d8899f1-eded-48b9-efbd-85b513a6620e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2335, 34)\n"]},{"output_type":"execute_result","data":{"text/plain":["   id   sensor_1  sensor_2   sensor_3   sensor_4   sensor_5   sensor_6  \\\n","0   1  -6.149463 -0.929714   9.058368  -7.017854  -2.958471   0.179233   \n","1   2  -2.238836 -1.003511   5.098079 -10.880357  -0.804562  -2.992123   \n","2   3  19.087934 -2.092514   0.946750 -21.831788   9.119235  17.853587   \n","3   4  -2.211629 -1.930904  21.888406  -3.067560  -0.240634   2.985056   \n","4   5   3.953852  2.964892 -36.044802   0.899838  26.930210  11.004409   \n","\n","    sensor_7   sensor_8   sensor_9  ...  sensor_24  sensor_25  sensor_26  \\\n","0  -0.956591  -0.972401   5.956213  ...  -7.026436  -6.006282  -6.005836   \n","1  26.972724  -8.900861  -5.968298  ...  -1.996714  -7.933806  -3.136773   \n","2 -21.069954 -15.933212  -9.016039  ...  -6.889685  54.052330  -6.109238   \n","3 -29.073369   0.200774  -1.043742  ...  -2.126170  -1.035526   2.178769   \n","4 -21.962423 -11.950189 -20.933785  ...  -2.051761  10.917567   1.905335   \n","\n","   sensor_27  sensor_28  sensor_29  sensor_30  sensor_31  sensor_32  target  \n","0   7.043084  21.884650  -3.064152  -5.247552  -6.026107 -11.990822       1  \n","1   8.774211  10.944759   9.858186  -0.969241  -3.935553 -15.892421       1  \n","2  12.154595   6.095989 -40.195088  -3.958124  -8.079537  -5.160090       0  \n","3  10.032723  -1.010897  -3.912848  -2.980338 -12.983597  -3.001077       1  \n","4 -13.004707  17.169552   2.105194   3.967986  11.861657 -27.088846       2  \n","\n","[5 rows x 34 columns]"],"text/html":["\n","  <div id=\"df-55734f80-aeb8-4b2a-893b-7c1e4935f749\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sensor_1</th>\n","      <th>sensor_2</th>\n","      <th>sensor_3</th>\n","      <th>sensor_4</th>\n","      <th>sensor_5</th>\n","      <th>sensor_6</th>\n","      <th>sensor_7</th>\n","      <th>sensor_8</th>\n","      <th>sensor_9</th>\n","      <th>...</th>\n","      <th>sensor_24</th>\n","      <th>sensor_25</th>\n","      <th>sensor_26</th>\n","      <th>sensor_27</th>\n","      <th>sensor_28</th>\n","      <th>sensor_29</th>\n","      <th>sensor_30</th>\n","      <th>sensor_31</th>\n","      <th>sensor_32</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>-6.149463</td>\n","      <td>-0.929714</td>\n","      <td>9.058368</td>\n","      <td>-7.017854</td>\n","      <td>-2.958471</td>\n","      <td>0.179233</td>\n","      <td>-0.956591</td>\n","      <td>-0.972401</td>\n","      <td>5.956213</td>\n","      <td>...</td>\n","      <td>-7.026436</td>\n","      <td>-6.006282</td>\n","      <td>-6.005836</td>\n","      <td>7.043084</td>\n","      <td>21.884650</td>\n","      <td>-3.064152</td>\n","      <td>-5.247552</td>\n","      <td>-6.026107</td>\n","      <td>-11.990822</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>-2.238836</td>\n","      <td>-1.003511</td>\n","      <td>5.098079</td>\n","      <td>-10.880357</td>\n","      <td>-0.804562</td>\n","      <td>-2.992123</td>\n","      <td>26.972724</td>\n","      <td>-8.900861</td>\n","      <td>-5.968298</td>\n","      <td>...</td>\n","      <td>-1.996714</td>\n","      <td>-7.933806</td>\n","      <td>-3.136773</td>\n","      <td>8.774211</td>\n","      <td>10.944759</td>\n","      <td>9.858186</td>\n","      <td>-0.969241</td>\n","      <td>-3.935553</td>\n","      <td>-15.892421</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>19.087934</td>\n","      <td>-2.092514</td>\n","      <td>0.946750</td>\n","      <td>-21.831788</td>\n","      <td>9.119235</td>\n","      <td>17.853587</td>\n","      <td>-21.069954</td>\n","      <td>-15.933212</td>\n","      <td>-9.016039</td>\n","      <td>...</td>\n","      <td>-6.889685</td>\n","      <td>54.052330</td>\n","      <td>-6.109238</td>\n","      <td>12.154595</td>\n","      <td>6.095989</td>\n","      <td>-40.195088</td>\n","      <td>-3.958124</td>\n","      <td>-8.079537</td>\n","      <td>-5.160090</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>-2.211629</td>\n","      <td>-1.930904</td>\n","      <td>21.888406</td>\n","      <td>-3.067560</td>\n","      <td>-0.240634</td>\n","      <td>2.985056</td>\n","      <td>-29.073369</td>\n","      <td>0.200774</td>\n","      <td>-1.043742</td>\n","      <td>...</td>\n","      <td>-2.126170</td>\n","      <td>-1.035526</td>\n","      <td>2.178769</td>\n","      <td>10.032723</td>\n","      <td>-1.010897</td>\n","      <td>-3.912848</td>\n","      <td>-2.980338</td>\n","      <td>-12.983597</td>\n","      <td>-3.001077</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>3.953852</td>\n","      <td>2.964892</td>\n","      <td>-36.044802</td>\n","      <td>0.899838</td>\n","      <td>26.930210</td>\n","      <td>11.004409</td>\n","      <td>-21.962423</td>\n","      <td>-11.950189</td>\n","      <td>-20.933785</td>\n","      <td>...</td>\n","      <td>-2.051761</td>\n","      <td>10.917567</td>\n","      <td>1.905335</td>\n","      <td>-13.004707</td>\n","      <td>17.169552</td>\n","      <td>2.105194</td>\n","      <td>3.967986</td>\n","      <td>11.861657</td>\n","      <td>-27.088846</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55734f80-aeb8-4b2a-893b-7c1e4935f749')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55734f80-aeb8-4b2a-893b-7c1e4935f749 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55734f80-aeb8-4b2a-893b-7c1e4935f749');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["x = [\"data_train\", \"data test\"]\n","y = [data_train.shape[0], data_test.shape[0]]\n","ax = sns.barplot(x=x, y=y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"e74NVGl_vCHs","executionInfo":{"status":"ok","timestamp":1647585629114,"user_tz":-540,"elapsed":18,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"fe2df87d-cd2b-4e7b-9dd5-128ca7e51e23"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPGElEQVR4nO3cfYxldX3H8fenrPiEAsqE0l3sbnSjXTX1YYpUakvEAFLrblM1tEZXs+22CT7Gh2pti1VIMBKp2mqzuhQ0VqBoy/rQUgKaRhuRXUAUEJlAhN0gjOyCT0Fd/faP+xu8TGZ2ZpbZOwO/9yuZzDm/h3N+Z3LP5575nXNvqgpJUh9+bakHIEkaHUNfkjpi6EtSRwx9SeqIoS9JHVmx1APYlyOOOKJWr1691MOQpIeUHTt2fL+qxmaqW9ahv3r1arZv377Uw5Ckh5Qk352tzukdSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyLL+RK70cHbbe5651EPQMvSkv//mAd2+V/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JF5hX6SNye5Psm3knw6yaOSrElyZZKJJBcmObi1fWRbn2j1q4e2885WflOSkw7MIUmSZjNn6CdZCbwBGK+qZwAHAacC7wPOqaqnAHuATa3LJmBPKz+ntSPJutbv6cDJwEeSHLS4hyNJ2pf5Tu+sAB6dZAXwGOAO4IXAxa3+fGBDW17f1mn1JyRJK7+gqn5aVbcCE8AxD/4QJEnzNWfoV9Uu4GzgNgZhfy+wA7inqva2ZjuBlW15JXB767u3tX/icPkMfSRJIzCf6Z3DGVylrwF+A3gsg+mZAyLJ5iTbk2yfnJw8ULuRpC7NZ3rnRcCtVTVZVT8HPgscBxzWpnsAVgG72vIu4GiAVn8ocPdw+Qx97ldVW6pqvKrGx8bG9uOQJEmzmU/o3wYcm+QxbW7+BOAG4EvAy1qbjcAlbXlbW6fVX1FV1cpPbU/3rAHWAl9fnMOQJM3HirkaVNWVSS4Grgb2AtcAW4AvABckOaOVbW1dtgKfTDIB7GbwxA5VdX2Sixi8YewFTquqXyzy8UiS9mHO0AeoqtOB06cV38IMT99U1X3Ay2fZzpnAmQscoyRpkfiJXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZF6hn+SwJBcn+XaSG5P8bpInJLksyc3t9+GtbZJ8KMlEkuuSPGdoOxtb+5uTbDxQByVJmtl8r/Q/CPx3VT0N+G3gRuAdwOVVtRa4vK0DvBhY2342Ax8FSPIE4HTgecAxwOlTbxSSpNGYM/STHAr8PrAVoKp+VlX3AOuB81uz84ENbXk98Ika+BpwWJKjgJOAy6pqd1XtAS4DTl7Uo5Ek7dN8rvTXAJPAvya5JsnHkzwWOLKq7mhtvgcc2ZZXArcP9d/ZymYrf4Akm5NsT7J9cnJyYUcjSdqn+YT+CuA5wEer6tnAj/nVVA4AVVVALcaAqmpLVY1X1fjY2NhibFKS1Mwn9HcCO6vqyrZ+MYM3gTvbtA3t912tfhdw9FD/Va1stnJJ0ojMGfpV9T3g9iRPbUUnADcA24CpJ3A2Ape05W3Aq9tTPMcC97ZpoEuBE5Mc3m7gntjKJEkjsmKe7V4PfCrJwcAtwGsZvGFclGQT8F3gFa3tF4FTgAngJ60tVbU7yXuBq1q791TV7kU5CknSvMwr9KvqWmB8hqoTZmhbwGmzbOdc4NyFDFCStHj8RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSReYd+koOSXJPk8219TZIrk0wkuTDJwa38kW19otWvHtrGO1v5TUlOWuyDkSTt20Ku9N8I3Di0/j7gnKp6CrAH2NTKNwF7Wvk5rR1J1gGnAk8HTgY+kuSgBzd8SdJCzCv0k6wC/hD4eFsP8ELg4tbkfGBDW17f1mn1J7T264ELquqnVXUrMAEcsxgHIUman/le6f8j8Hbgl239icA9VbW3re8EVrbllcDtAK3+3tb+/vIZ+twvyeYk25Nsn5ycXMChSJLmMmfoJ3kJcFdV7RjBeKiqLVU1XlXjY2Njo9ilJHVjxTzaHAe8NMkpwKOAxwMfBA5LsqJdza8CdrX2u4CjgZ1JVgCHAncPlU8Z7iNJGoE5r/Sr6p1VtaqqVjO4EXtFVb0S+BLwstZsI3BJW97W1mn1V1RVtfJT29M9a4C1wNcX7UgkSXOaz5X+bP4auCDJGcA1wNZWvhX4ZJIJYDeDNwqq6vokFwE3AHuB06rqFw9i/5KkBVpQ6FfVl4Evt+VbmOHpm6q6D3j5LP3PBM5c6CAlSYvDT+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRFUs9gAPtuW/7xFIPQcvQjve/eqmHIC0Jr/QlqSOGviR1xNCXpI7MGfpJjk7ypSQ3JLk+yRtb+ROSXJbk5vb78FaeJB9KMpHkuiTPGdrWxtb+5iQbD9xhSZJmMp8r/b3AW6pqHXAscFqSdcA7gMurai1weVsHeDGwtv1sBj4KgzcJ4HTgecAxwOlTbxSSpNGYM/Sr6o6qurot/xC4EVgJrAfOb83OBza05fXAJ2rga8BhSY4CTgIuq6rdVbUHuAw4eVGPRpK0Twua00+yGng2cCVwZFXd0aq+BxzZllcCtw9129nKZiuXJI3IvEM/ySHAZ4A3VdUPhuuqqoBajAEl2Zxke5Ltk5OTi7FJSVIzr9BP8ggGgf+pqvpsK76zTdvQft/VyncBRw91X9XKZit/gKraUlXjVTU+Nja2kGORJM1hPk/vBNgK3FhVHxiq2gZMPYGzEbhkqPzV7SmeY4F72zTQpcCJSQ5vN3BPbGWSpBGZz9cwHAe8Cvhmkmtb2d8AZwEXJdkEfBd4Rav7InAKMAH8BHgtQFXtTvJe4KrW7j1VtXtRjkKSNC9zhn5VfQXILNUnzNC+gNNm2da5wLkLGaAkafH4iVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTkoZ/k5CQ3JZlI8o5R71+SejbS0E9yEPDPwIuBdcCfJlk3yjFIUs9GfaV/DDBRVbdU1c+AC4D1Ix6DJHVrxYj3txK4fWh9J/C84QZJNgOb2+qPktw0orH14Ajg+0s9iOUgZ29c6iHogXxtTjk9i7GV35ytYtShP6eq2gJsWepxPBwl2V5V40s9Dmk6X5ujM+rpnV3A0UPrq1qZJGkERh36VwFrk6xJcjBwKrBtxGOQpG6NdHqnqvYmeR1wKXAQcG5VXT/KMXTOaTMtV742RyRVtdRjkCSNiJ/IlaSOGPqS1BFDX9J+S/LuJG+do82GhX7yPsnxSZ6/n2NaneTP9qdvDwz9ZWquk2l/TqQH2zfJS/2+JO2HDQy+dmUhjgf2K/SB1YChPwtD/6Frf06kOfsmmfWJrqraVlVn7ec+9TCR5F1JvpPkK8BTh8r/IslVSb6R5DNJHtOu1l8KvD/JtUmePFO7adtfDfwV8ObW5wVJxlrbq9rPca3tH7Q21ya5JsnjgLOAF7SyN4/oz/KQ4dM7y0iSdwEbgbsYfF3FDuBeBl9LcTAwAbwKeBbw+VZ3L/AnwAunt6uqn8ywj+fP0HcrcC3we8Cnge8Af9u2dTfwyqq6M8lrgPGqel2S84AfAOPArwNvr6qLF/UPomUnyXOB8xh8fcoK4GrgX6rq7CRPrKq7W7szgDur6sPttfL5qdfHbO2m7efdwI+q6uy2/m/AR6rqK0meBFxaVb+V5HPAWVX11SSHAPcxeB2/tapecmD/Gg9Ny+5rGHrVTqZTGQT61Mm0A/hsVX2stTkD2NROpG088ES6Z3o74MPT91NV/zdDX4CDpz4Gn+Rw4NiqqiR/DrwdeMsMwz6KwQn2NAYfsjP0H/5eAPzH1AVFey1NeUZ77R0GHMLg8zgzmW+7YS8C1rXXKsDjW8h/FfhAkk8xOFd2DrXRDAz95WO2k+lAnkjDLhxaXgVcmOQoBlf7t87S5z+r6pfADUmOXOD+9PBzHrChqr7R/is8/kG2G/ZrDC5E7ptWflaSLwCnAF9NctLCh90X5/SXv/OA11XVM4F/AB71INvN5sdDyx8G/qlt6y/3sa2fDi17edWH/wU2JHl0mz//o6G6xwF3JHkE8Mqh8h+2urnaDZve53+A10+tJHlW+/3kqvpmVb2Pwde8PG2Gvhpi6C8fs51Mi3kizdZ3ukP51Rfh+R3Eul9VXc3gv8JvAP/FIGin/B1wJYMpl28PlV8AvK3daH3yPtoN+xzwx1M3coE3AONJrktyA4MbvQBvSvKtJNcBP29jug74RbtR7I3cabyRu4xMu5F7G4N5/R8zmFOfZHCiPK6qXtOeXvgYg6vtlwEnztRulv1M77uVwY2v7a1+PXAOsAe4Avidqjp+hhu5w/cFflRVhyzqH0TSojP0JakjTu9IUkd8eudhrE0XvXxa8b9X1ZlLMR5JS8/pHUnqiNM7ktQRQ1+SOmLoS1JHDH1J6sj/A2UH8cpegDLPAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["train_X = data_train.drop(['target', 'id'], axis = 1)\n","train_X = (train_X+130)/260 \n","train_X = np.array(train_X)\n","train_X = np.array(train_X).reshape(-1, 8, 4, 1)\n","\n","train_Y = data_train['target']\n","train_Y = np.array(train_Y)\n","\n","X_test = data_test.drop('id', axis = 1)\n","X_test = (X_test+130)/260\n","X_test = np.array(X_test).reshape(-1, 8, 4, 1)"],"metadata":{"id":"HN_jGQOpvEAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"min :\", train_X.min(), \"\\nmax :\", train_X.max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fpMRzCuvFcr","executionInfo":{"status":"ok","timestamp":1647585629686,"user_tz":-540,"elapsed":19,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"c6c69ced-9190-4b27-c2f6-b62c9aeed1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["min : 0.008470580769230742 \n","max : 0.9890809815384616\n"]}]},{"cell_type":"code","source":["train_X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTM7oPF4vHSc","executionInfo":{"status":"ok","timestamp":1647585629687,"user_tz":-540,"elapsed":18,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"0fb4a0ca-d61d-4ec9-bcea-ef4382b8e1ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2335, 8, 4, 1)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train_Y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kZn56clvJrF","executionInfo":{"status":"ok","timestamp":1647585629688,"user_tz":-540,"elapsed":15,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"e48a5db1-413e-4b77-c777-88cd510f2141"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2335,)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["def identity_block(X, filters, kernel_size):\n","    X_shortcut = X\n","    \n","    X = tf.keras.layers.Conv2D(filters, (1,1), padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    X = tf.keras.layers.Conv2D(filters, kernel_size, padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    X = tf.keras.layers.Conv2D(filters*4, (1,1), padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","    \n","    # Add\n","    X = tf.keras.layers.Add()([X, X_shortcut])\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    return X"],"metadata":{"id":"lP3_bGVjvMHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convolutional_block(X, filters, kernel_size):\n","    X_shortcut = X\n","    \n","    X = tf.keras.layers.Conv2D(filters, (1,1), padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    X = tf.keras.layers.Conv2D(filters, kernel_size, padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    X = tf.keras.layers.Conv2D(filters*4, (1,1), padding='SAME')(X)\n","    X = tf.keras.layers.BatchNormalization()(X)\n","\n","    X_shortcut = tf.keras.layers.Conv2D(filters*4, (1,1), padding='SAME')(X_shortcut) #use 1x1 conv to make shape same\n","    X_shortcut = tf.keras.layers.BatchNormalization()(X_shortcut)\n","    \n","    # Add\n","    X = tf.keras.layers.Add()([X, X_shortcut])\n","    X = tf.keras.layers.Activation('gelu')(X)\n","    \n","    return X"],"metadata":{"id":"q48x5wu3vOFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def CustomModel(input_shape = (8, 4, 1), classes = 4):\n","    X_input = tf.keras.layers.Input(input_shape)\n","    X = X_input\n","    \n","    X = convolutional_block(X, 128, (3,2)) #(3,3) 보다는 직사각형 이미지이기때문에 (3,2)처럼 직사각형 필터를 사용\n","    X = identity_block(X, 128, (3,2))\n","    X = identity_block(X, 128, (3,2))\n","    \n","    X = tf.keras.layers.AveragePooling2D(2,2)(X) #Max보다는 Average pool이 성능이 잘나옴\n","\n","    X = convolutional_block(X, 256, (2,1)) #(2,1) 직사각형 필터를 사용\n","    X = identity_block(X, 256, (2,1))\n","    X = identity_block(X, 256, (2,1))\n","    \n","    X = tf.keras.layers.GlobalAveragePooling2D()(X) #Flatten 대신 사용\n","    \n","    X = tf.keras.layers.Dense(128, activation = \"relu\")(X)\n","    \n","    X = tf.keras.layers.Dropout(0.5)(X)\n","    \n","    X = tf.keras.layers.Dense(classes, activation = \"softmax\")(X)\n","\n","    model = tf.keras.models.Model(inputs = X_input, outputs = X, name = \"CustomModel\")\n","    \n","    return model"],"metadata":{"id":"NNxRF460vQR-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.utils import shuffle\n","\n","skf = StratifiedKFold(n_splits = 15, random_state = 1233, shuffle = True) #총 15번의 fold 진행\n","n = 0 #x번째 fold인지 기록\n","\n","cnn_pred = [] #모델의 예측값 모두 저장\n","\n","for train_index, valid_index in skf.split(train_X, train_Y):\n","    n += 1\n","    X_train, X_valid = train_X[train_index], train_X[valid_index]\n","    y_train, y_valid = train_Y[train_index], train_Y[valid_index]\n","\n","    ### Swap Noise ###\n","    X_train_mix = np.array(X_train)\n","    for x in range(X_train_mix.shape[0]):\n","        for i in range(5):\n","            y = np.random.randint(0, 8)\n","            z = np.random.randint(0, 4)\n","            \n","            while True:\n","                c = np.random.randint(0, X_train_mix.shape[0]-1)\n","                if ((x != c)and(y_train[x] == y_train[c])):\n","                    break\n","                    \n","            X_train_mix[x][y][z] = X_train[c][y][z]\n","\n","    X_train = np.append(X_train, X_train_mix, axis = 0)\n","    y_train = np.append(y_train, y_train, axis = 0)\n","    \n","    ### Mix Data Again ####\n","    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n","    \n","    y_train = tf.one_hot(y_train, 4)\n","    y_train = tf.reshape(y_train, [-1,4])\n","    y_train = np.array(y_train)\n","    \n","    y_valid = tf.one_hot(y_valid, 4)\n","    y_valid = tf.reshape(y_valid, [-1,4])\n","    y_valid = np.array(y_valid)\n","    \n","    ### Create Model ###\n","    model = CustomModel()\n","    \n","    ### Compile Model ###\n","    model.compile(optimizer='Rmsprop', # 무난한 adam 사용\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","    ### Create callbacks ###\n","    filename = 'CNN-checkpoint.h5'\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(filename,             # file명을 지정합니다\n","                                                    monitor='val_accuracy',   # val_accuracy 값이 개선되었을때 호출됩니다\n","                                                    verbose=1,            # 로그를 출력합니다 0일경우 출력 X\n","                                                    save_best_only=True,  # 가장 best 값만 저장합니다\n","                                                    mode='auto'           # auto는 알아서 best를 찾습니다. min/max (loss->min, accuracy->max)\n","                                                   )\n","    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val loss) \n","                                  patience=12,         # 12 Epoch동안 개선되지 않는다면 종료\n","                                 )\n","    reduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n","        monitor='val_accuracy', # val_accuracy 값이 개선되었을때 호출됩니다\n","        factor=0.5, # learning rate이 0.5배 줄어듬\n","        patience=6, # 6 Epoch동안 개선되지 않는다면 호출\n","    )\n","    \n","    ### fit model ###\n","    data = model.fit(X_train, \n","                     y_train, \n","                     validation_data=(X_valid, y_valid), \n","                     epochs=60, \n","                     batch_size=32, # batch size가 32일때 가장 좋은 성능을 보임\n","                     callbacks=[reduceLR, earlystopping, checkpoint],\n","                     verbose=1 # 로그 출력을 없앰, 어짜피 아래 print에서 한번에 best_accuracy만 출력할것이기 때문이다.\n","                    )\n","    \n","    idx = data.history['val_accuracy'].index(max(data.history['val_accuracy']))\n","    \n","    print(\"fold %d / val_accuracy : %0.4f / val_loss : %0.4f\" %(n,\n","                                                                data.history['val_accuracy'][idx], \n","                                                                data.history['val_loss'][idx]))\n","    \n","    ### predict model ###\n","    model = tf.keras.models.load_model('./CNN-checkpoint.h5') # best accuracy를 기록한 모델을 불러옴\n","    pred_proba = model.predict(X_test) # 테스트 셋에 대한 예측 수행\n","    cnn_pred.append(pred_proba) # 예측값을 cnn_pred 리스트에 저장"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MsFypoIwvSPF","executionInfo":{"status":"ok","timestamp":1647595262413,"user_tz":-540,"elapsed":2710765,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"6dbd8a79-b58f-484f-abd0-f1434e369c71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.1327 - accuracy: 0.6055\n","Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 15s 46ms/step - loss: 1.1317 - accuracy: 0.6058 - val_loss: 1.8751 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.7806\n","Epoch 2: val_accuracy did not improve from 0.33333\n","137/137 [==============================] - 5s 37ms/step - loss: 0.6152 - accuracy: 0.7806 - val_loss: 2.6599 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.8157\n","Epoch 3: val_accuracy improved from 0.33333 to 0.45513, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 39ms/step - loss: 0.5155 - accuracy: 0.8157 - val_loss: 2.0398 - val_accuracy: 0.4551 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8433\n","Epoch 4: val_accuracy improved from 0.45513 to 0.66026, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4461 - accuracy: 0.8433 - val_loss: 1.3785 - val_accuracy: 0.6603 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8529\n","Epoch 5: val_accuracy did not improve from 0.66026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.4176 - accuracy: 0.8529 - val_loss: 1.2421 - val_accuracy: 0.6090 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.8637\n","Epoch 6: val_accuracy improved from 0.66026 to 0.76282, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.3948 - accuracy: 0.8637 - val_loss: 1.2101 - val_accuracy: 0.7628 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8740\n","Epoch 7: val_accuracy improved from 0.76282 to 0.79487, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.3524 - accuracy: 0.8740 - val_loss: 0.8452 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.8878\n","Epoch 8: val_accuracy did not improve from 0.79487\n","137/137 [==============================] - 5s 37ms/step - loss: 0.3243 - accuracy: 0.8878 - val_loss: 0.6140 - val_accuracy: 0.7821 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9011\n","Epoch 9: val_accuracy improved from 0.79487 to 0.87179, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2795 - accuracy: 0.9011 - val_loss: 0.4611 - val_accuracy: 0.8718 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9039\n","Epoch 10: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.2562 - accuracy: 0.9039 - val_loss: 0.5250 - val_accuracy: 0.8718 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9133\n","Epoch 11: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.2423 - accuracy: 0.9133 - val_loss: 1.0839 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9169\n","Epoch 12: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.2371 - accuracy: 0.9169 - val_loss: 1.0870 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9275\n","Epoch 13: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.2008 - accuracy: 0.9275 - val_loss: 0.9976 - val_accuracy: 0.7564 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9309\n","Epoch 14: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.1936 - accuracy: 0.9309 - val_loss: 1.1468 - val_accuracy: 0.7756 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9355\n","Epoch 15: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.1805 - accuracy: 0.9355 - val_loss: 0.8406 - val_accuracy: 0.8718 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9615\n","Epoch 16: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.1097 - accuracy: 0.9615 - val_loss: 0.6596 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9695\n","Epoch 17: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0880 - accuracy: 0.9695 - val_loss: 0.8449 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9736\n","Epoch 18: val_accuracy improved from 0.87179 to 0.87821, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 42ms/step - loss: 0.0821 - accuracy: 0.9736 - val_loss: 0.6397 - val_accuracy: 0.8782 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9807\n","Epoch 19: val_accuracy improved from 0.87821 to 0.88462, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.8377 - val_accuracy: 0.8846 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9805\n","Epoch 20: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.8321 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9821\n","Epoch 21: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 1.0670 - val_accuracy: 0.8654 - lr: 5.0000e-04\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9846\n","Epoch 22: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.8332 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 23/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9851\n","Epoch 23: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 1.3167 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9874\n","Epoch 24: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0462 - accuracy: 0.9874 - val_loss: 0.9483 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9869\n","Epoch 25: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 1.6943 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9920\n","Epoch 26: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.9236 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 27/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9952\n","Epoch 27: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0268 - accuracy: 0.9952 - val_loss: 1.0868 - val_accuracy: 0.8526 - lr: 2.5000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9977\n","Epoch 28: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.9618 - val_accuracy: 0.8782 - lr: 2.5000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9982\n","Epoch 29: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.1521 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9961\n","Epoch 30: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: 1.1912 - val_accuracy: 0.8718 - lr: 2.5000e-04\n","Epoch 31/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9977\n","Epoch 31: val_accuracy did not improve from 0.88462\n","137/137 [==============================] - 6s 43ms/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 1.3918 - val_accuracy: 0.8718 - lr: 2.5000e-04\n","fold 1 / val_accuracy : 0.8846 / val_loss : 0.8377\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0495 - accuracy: 0.6260\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 46ms/step - loss: 1.0495 - accuracy: 0.6260 - val_loss: 2.7780 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7848\n","Epoch 2: val_accuracy improved from 0.25000 to 0.42308, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.6099 - accuracy: 0.7848 - val_loss: 1.5136 - val_accuracy: 0.4231 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8187\n","Epoch 3: val_accuracy did not improve from 0.42308\n","137/137 [==============================] - 5s 38ms/step - loss: 0.5253 - accuracy: 0.8187 - val_loss: 2.7393 - val_accuracy: 0.3397 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.8348\n","Epoch 4: val_accuracy improved from 0.42308 to 0.62179, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4735 - accuracy: 0.8348 - val_loss: 1.5919 - val_accuracy: 0.6218 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8497\n","Epoch 5: val_accuracy improved from 0.62179 to 0.80128, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4419 - accuracy: 0.8497 - val_loss: 0.4412 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8639\n","Epoch 6: val_accuracy improved from 0.80128 to 0.83333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3970 - accuracy: 0.8639 - val_loss: 0.5971 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8678\n","Epoch 7: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 37ms/step - loss: 0.3789 - accuracy: 0.8678 - val_loss: 0.7888 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8775\n","Epoch 8: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 37ms/step - loss: 0.3618 - accuracy: 0.8775 - val_loss: 0.8648 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.8818\n","Epoch 9: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3379 - accuracy: 0.8818 - val_loss: 1.1106 - val_accuracy: 0.7436 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.8981\n","Epoch 10: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2882 - accuracy: 0.8981 - val_loss: 1.1226 - val_accuracy: 0.7692 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.8983\n","Epoch 11: val_accuracy improved from 0.83333 to 0.85256, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.2832 - accuracy: 0.8983 - val_loss: 0.5014 - val_accuracy: 0.8526 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9156\n","Epoch 12: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2437 - accuracy: 0.9156 - val_loss: 1.5691 - val_accuracy: 0.6795 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9204\n","Epoch 13: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2336 - accuracy: 0.9204 - val_loss: 1.3659 - val_accuracy: 0.6859 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9341\n","Epoch 14: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1946 - accuracy: 0.9341 - val_loss: 1.6692 - val_accuracy: 0.6538 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9302\n","Epoch 15: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 37ms/step - loss: 0.2022 - accuracy: 0.9302 - val_loss: 0.7637 - val_accuracy: 0.8269 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9335\n","Epoch 16: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1811 - accuracy: 0.9335 - val_loss: 2.1150 - val_accuracy: 0.6346 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9445\n","Epoch 17: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1547 - accuracy: 0.9445 - val_loss: 1.1094 - val_accuracy: 0.8397 - lr: 0.0010\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9672\n","Epoch 18: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0965 - accuracy: 0.9672 - val_loss: 0.8063 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9768\n","Epoch 19: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0711 - accuracy: 0.9768 - val_loss: 1.1433 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9814\n","Epoch 20: val_accuracy improved from 0.85256 to 0.86538, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.0535 - accuracy: 0.9814 - val_loss: 0.9787 - val_accuracy: 0.8654 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9832\n","Epoch 21: val_accuracy improved from 0.86538 to 0.89744, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.7667 - val_accuracy: 0.8974 - lr: 5.0000e-04\n","Epoch 22/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9830\n","Epoch 22: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.7714 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 23/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9842\n","Epoch 23: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 1.1096 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 24/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9855\n","Epoch 24: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 1.2507 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9883\n","Epoch 25: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0392 - accuracy: 0.9883 - val_loss: 1.2599 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9874\n","Epoch 26: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0450 - accuracy: 0.9874 - val_loss: 1.0440 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 27/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9876\n","Epoch 27: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 0.8355 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9959\n","Epoch 28: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.0314 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9966\n","Epoch 29: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.1557 - val_accuracy: 0.8462 - lr: 2.5000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9959\n","Epoch 30: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.0813 - val_accuracy: 0.8526 - lr: 2.5000e-04\n","Epoch 31/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9968\n","Epoch 31: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 37ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 1.0931 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 32/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9963\n","Epoch 32: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.0507 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 33/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9972\n","Epoch 33: val_accuracy did not improve from 0.89744\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 1.1381 - val_accuracy: 0.8718 - lr: 2.5000e-04\n","fold 2 / val_accuracy : 0.8974 / val_loss : 0.7667\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0504 - accuracy: 0.6301\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 46ms/step - loss: 1.0504 - accuracy: 0.6301 - val_loss: 1.9285 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.5893 - accuracy: 0.7909\n","Epoch 2: val_accuracy improved from 0.24359 to 0.26282, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.5895 - accuracy: 0.7907 - val_loss: 2.8139 - val_accuracy: 0.2628 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8279\n","Epoch 3: val_accuracy improved from 0.26282 to 0.48718, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.5019 - accuracy: 0.8279 - val_loss: 1.8055 - val_accuracy: 0.4872 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.8453\n","Epoch 4: val_accuracy improved from 0.48718 to 0.59615, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4712 - accuracy: 0.8453 - val_loss: 1.5866 - val_accuracy: 0.5962 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.8605\n","Epoch 5: val_accuracy improved from 0.59615 to 0.74359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3996 - accuracy: 0.8605 - val_loss: 0.8879 - val_accuracy: 0.7436 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8642\n","Epoch 6: val_accuracy improved from 0.74359 to 0.83333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3911 - accuracy: 0.8642 - val_loss: 0.6133 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8756\n","Epoch 7: val_accuracy improved from 0.83333 to 0.85897, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3690 - accuracy: 0.8756 - val_loss: 0.7539 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.8883\n","Epoch 8: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3192 - accuracy: 0.8883 - val_loss: 0.8593 - val_accuracy: 0.7692 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8938\n","Epoch 9: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3279 - accuracy: 0.8938 - val_loss: 0.5534 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.9055\n","Epoch 10: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2752 - accuracy: 0.9055 - val_loss: 0.8668 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9105\n","Epoch 11: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2730 - accuracy: 0.9105 - val_loss: 0.4959 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.9149\n","Epoch 12: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2431 - accuracy: 0.9149 - val_loss: 2.0427 - val_accuracy: 0.6474 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9252\n","Epoch 13: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2079 - accuracy: 0.9252 - val_loss: 1.0207 - val_accuracy: 0.7692 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9470\n","Epoch 14: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1521 - accuracy: 0.9470 - val_loss: 1.0168 - val_accuracy: 0.7821 - lr: 5.0000e-04\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9566\n","Epoch 15: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1165 - accuracy: 0.9566 - val_loss: 0.8251 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9635\n","Epoch 16: val_accuracy improved from 0.85897 to 0.86538, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.1071 - accuracy: 0.9635 - val_loss: 0.8322 - val_accuracy: 0.8654 - lr: 5.0000e-04\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9665\n","Epoch 17: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0935 - accuracy: 0.9665 - val_loss: 0.9210 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9704\n","Epoch 18: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0841 - accuracy: 0.9704 - val_loss: 1.0731 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9727\n","Epoch 19: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 1.1650 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9752\n","Epoch 20: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0794 - accuracy: 0.9752 - val_loss: 0.9878 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9780\n","Epoch 21: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 1.1814 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 22/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 0.9789\n","Epoch 22: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 1.1574 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 23/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9826\n","Epoch 23: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 1.3650 - val_accuracy: 0.8077 - lr: 2.5000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9933\n","Epoch 24: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 1.4667 - val_accuracy: 0.8462 - lr: 2.5000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9911\n","Epoch 25: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 1.4472 - val_accuracy: 0.8205 - lr: 2.5000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9931\n","Epoch 26: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 1.2448 - val_accuracy: 0.8333 - lr: 2.5000e-04\n","Epoch 27/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9947\n","Epoch 27: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 1.4123 - val_accuracy: 0.8462 - lr: 2.5000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9966\n","Epoch 28: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 1.6321 - val_accuracy: 0.8141 - lr: 2.5000e-04\n","fold 3 / val_accuracy : 0.8654 / val_loss : 0.8322\n","Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.1042 - accuracy: 0.5993\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 46ms/step - loss: 1.1035 - accuracy: 0.5996 - val_loss: 3.2790 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.7848\n","Epoch 2: val_accuracy improved from 0.25000 to 0.37821, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.6108 - accuracy: 0.7848 - val_loss: 1.8421 - val_accuracy: 0.3782 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.8180\n","Epoch 3: val_accuracy improved from 0.37821 to 0.42949, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.5195 - accuracy: 0.8180 - val_loss: 2.0596 - val_accuracy: 0.4295 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8421\n","Epoch 4: val_accuracy improved from 0.42949 to 0.67308, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4622 - accuracy: 0.8421 - val_loss: 1.3012 - val_accuracy: 0.6731 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8515\n","Epoch 5: val_accuracy improved from 0.67308 to 0.82051, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4401 - accuracy: 0.8515 - val_loss: 0.4479 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8632\n","Epoch 6: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3900 - accuracy: 0.8632 - val_loss: 0.9227 - val_accuracy: 0.7628 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8782\n","Epoch 7: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3552 - accuracy: 0.8782 - val_loss: 0.8873 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8846\n","Epoch 8: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3467 - accuracy: 0.8846 - val_loss: 1.0556 - val_accuracy: 0.7372 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8958\n","Epoch 9: val_accuracy improved from 0.82051 to 0.83333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.2991 - accuracy: 0.8958 - val_loss: 0.8520 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8972\n","Epoch 10: val_accuracy improved from 0.83333 to 0.85897, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.3232 - accuracy: 0.8972 - val_loss: 0.6286 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9045\n","Epoch 11: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2731 - accuracy: 0.9045 - val_loss: 0.6346 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9169\n","Epoch 12: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2438 - accuracy: 0.9169 - val_loss: 0.5407 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9259\n","Epoch 13: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2299 - accuracy: 0.9259 - val_loss: 1.0788 - val_accuracy: 0.7308 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9314\n","Epoch 14: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1940 - accuracy: 0.9314 - val_loss: 0.6026 - val_accuracy: 0.8269 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9332\n","Epoch 15: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2087 - accuracy: 0.9332 - val_loss: 0.7926 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9417\n","Epoch 16: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1598 - accuracy: 0.9417 - val_loss: 0.9554 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9631\n","Epoch 17: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1176 - accuracy: 0.9631 - val_loss: 0.7684 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9699\n","Epoch 18: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0900 - accuracy: 0.9699 - val_loss: 0.6881 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9759\n","Epoch 19: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0678 - accuracy: 0.9759 - val_loss: 1.0073 - val_accuracy: 0.8013 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9803\n","Epoch 20: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0642 - accuracy: 0.9803 - val_loss: 1.0542 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9782\n","Epoch 21: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0592 - accuracy: 0.9782 - val_loss: 1.4293 - val_accuracy: 0.7885 - lr: 5.0000e-04\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9837\n","Epoch 22: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 1.1268 - val_accuracy: 0.8077 - lr: 5.0000e-04\n","fold 4 / val_accuracy : 0.8590 / val_loss : 0.6286\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.1097 - accuracy: 0.6145\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 45ms/step - loss: 1.1097 - accuracy: 0.6145 - val_loss: 2.1325 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.7868\n","Epoch 2: val_accuracy improved from 0.24359 to 0.33333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.6143 - accuracy: 0.7868 - val_loss: 1.7897 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.8277\n","Epoch 3: val_accuracy improved from 0.33333 to 0.38462, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.4959 - accuracy: 0.8277 - val_loss: 2.4772 - val_accuracy: 0.3846 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.8332\n","Epoch 4: val_accuracy improved from 0.38462 to 0.75641, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4637 - accuracy: 0.8332 - val_loss: 0.7276 - val_accuracy: 0.7564 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8559\n","Epoch 5: val_accuracy improved from 0.75641 to 0.85897, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4230 - accuracy: 0.8559 - val_loss: 0.4548 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8674\n","Epoch 6: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3784 - accuracy: 0.8674 - val_loss: 1.8278 - val_accuracy: 0.6603 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.8726\n","Epoch 7: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3404 - accuracy: 0.8726 - val_loss: 1.3674 - val_accuracy: 0.6667 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8848\n","Epoch 8: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3189 - accuracy: 0.8848 - val_loss: 0.6656 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8970\n","Epoch 9: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2944 - accuracy: 0.8970 - val_loss: 0.8070 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.9073\n","Epoch 10: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2693 - accuracy: 0.9073 - val_loss: 0.5885 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9130\n","Epoch 11: val_accuracy improved from 0.85897 to 0.86538, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.2370 - accuracy: 0.9130 - val_loss: 0.7331 - val_accuracy: 0.8654 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9185\n","Epoch 12: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2418 - accuracy: 0.9185 - val_loss: 1.4840 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.9289\n","Epoch 13: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.9497 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9312\n","Epoch 14: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2065 - accuracy: 0.9312 - val_loss: 1.0205 - val_accuracy: 0.7115 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9431\n","Epoch 15: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1884 - accuracy: 0.9431 - val_loss: 0.9224 - val_accuracy: 0.8397 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9447\n","Epoch 16: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1600 - accuracy: 0.9447 - val_loss: 1.0577 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9504\n","Epoch 17: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1505 - accuracy: 0.9504 - val_loss: 0.9164 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9733\n","Epoch 18: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0794 - accuracy: 0.9732 - val_loss: 0.8153 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9793\n","Epoch 19: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0601 - accuracy: 0.9793 - val_loss: 1.0583 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9803\n","Epoch 20: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0528 - accuracy: 0.9803 - val_loss: 1.1515 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9849\n","Epoch 21: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0570 - accuracy: 0.9849 - val_loss: 0.8093 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9867\n","Epoch 22: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0497 - accuracy: 0.9867 - val_loss: 0.9976 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 23/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9869\n","Epoch 23: val_accuracy improved from 0.86538 to 0.87179, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.0382 - accuracy: 0.9869 - val_loss: 1.1134 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9862\n","Epoch 24: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 1.1374 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9867\n","Epoch 25: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0463 - accuracy: 0.9867 - val_loss: 1.2520 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9876\n","Epoch 26: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 1.3937 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 27/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9915\n","Epoch 27: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 1.2986 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9885\n","Epoch 28: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 1.2690 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9922\n","Epoch 29: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.3552 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9947\n","Epoch 30: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 1.3144 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 31/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9959\n","Epoch 31: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 1.7298 - val_accuracy: 0.8397 - lr: 2.5000e-04\n","Epoch 32/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9959\n","Epoch 32: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0097 - accuracy: 0.9959 - val_loss: 1.4889 - val_accuracy: 0.8526 - lr: 2.5000e-04\n","Epoch 33/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n","Epoch 33: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.6453 - val_accuracy: 0.8269 - lr: 2.5000e-04\n","Epoch 34/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n","Epoch 34: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.4952 - val_accuracy: 0.8718 - lr: 2.5000e-04\n","Epoch 35/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n","Epoch 35: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 1.8491 - val_accuracy: 0.8718 - lr: 2.5000e-04\n","fold 5 / val_accuracy : 0.8718 / val_loss : 1.1134\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.6150\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 13s 46ms/step - loss: 1.0868 - accuracy: 0.6150 - val_loss: 3.2142 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.7877\n","Epoch 2: val_accuracy improved from 0.24359 to 0.25000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.6076 - accuracy: 0.7877 - val_loss: 2.6472 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 3/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.8074\n","Epoch 3: val_accuracy improved from 0.25000 to 0.44231, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5171 - accuracy: 0.8075 - val_loss: 1.6916 - val_accuracy: 0.4423 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8387\n","Epoch 4: val_accuracy improved from 0.44231 to 0.53205, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4574 - accuracy: 0.8387 - val_loss: 1.6063 - val_accuracy: 0.5321 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.8561\n","Epoch 5: val_accuracy improved from 0.53205 to 0.75000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4232 - accuracy: 0.8561 - val_loss: 0.7785 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8674\n","Epoch 6: val_accuracy improved from 0.75000 to 0.77564, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3862 - accuracy: 0.8674 - val_loss: 0.7507 - val_accuracy: 0.7756 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8756\n","Epoch 7: val_accuracy improved from 0.77564 to 0.82051, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.3560 - accuracy: 0.8756 - val_loss: 0.5128 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8839\n","Epoch 8: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3306 - accuracy: 0.8839 - val_loss: 0.6102 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.9034\n","Epoch 9: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2843 - accuracy: 0.9034 - val_loss: 1.0535 - val_accuracy: 0.6731 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9121\n","Epoch 10: val_accuracy did not improve from 0.82051\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2615 - accuracy: 0.9121 - val_loss: 0.8717 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9211\n","Epoch 11: val_accuracy improved from 0.82051 to 0.84615, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.2283 - accuracy: 0.9211 - val_loss: 0.9097 - val_accuracy: 0.8462 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9236\n","Epoch 12: val_accuracy did not improve from 0.84615\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2243 - accuracy: 0.9236 - val_loss: 0.8085 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9277\n","Epoch 13: val_accuracy did not improve from 0.84615\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2092 - accuracy: 0.9277 - val_loss: 1.0241 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9383\n","Epoch 14: val_accuracy did not improve from 0.84615\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1845 - accuracy: 0.9383 - val_loss: 1.7697 - val_accuracy: 0.6987 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9456\n","Epoch 15: val_accuracy did not improve from 0.84615\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1644 - accuracy: 0.9456 - val_loss: 1.6869 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9458\n","Epoch 16: val_accuracy did not improve from 0.84615\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1511 - accuracy: 0.9458 - val_loss: 1.2244 - val_accuracy: 0.8269 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9532\n","Epoch 17: val_accuracy improved from 0.84615 to 0.85256, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.1428 - accuracy: 0.9532 - val_loss: 1.0575 - val_accuracy: 0.8526 - lr: 0.0010\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9592\n","Epoch 18: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1301 - accuracy: 0.9592 - val_loss: 1.5325 - val_accuracy: 0.7628 - lr: 0.0010\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9589\n","Epoch 19: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1277 - accuracy: 0.9589 - val_loss: 1.3915 - val_accuracy: 0.7756 - lr: 0.0010\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9619\n","Epoch 20: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1255 - accuracy: 0.9619 - val_loss: 1.1768 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9651\n","Epoch 21: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1118 - accuracy: 0.9651 - val_loss: 1.1278 - val_accuracy: 0.7821 - lr: 0.0010\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9626\n","Epoch 22: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1117 - accuracy: 0.9626 - val_loss: 1.6073 - val_accuracy: 0.7821 - lr: 0.0010\n","Epoch 23/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9708\n","Epoch 23: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0981 - accuracy: 0.9704 - val_loss: 1.4552 - val_accuracy: 0.7692 - lr: 0.0010\n","Epoch 24/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9855\n","Epoch 24: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 1.3677 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 25/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9906\n","Epoch 25: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 1.2450 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 26/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9915\n","Epoch 26: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 1.4611 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 27/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9924\n","Epoch 27: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0274 - accuracy: 0.9924 - val_loss: 1.4863 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9945\n","Epoch 28: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0234 - accuracy: 0.9945 - val_loss: 1.5489 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 29/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9915\n","Epoch 29: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 1.7231 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","fold 6 / val_accuracy : 0.8526 / val_loss : 1.0575\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.6251\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 13s 46ms/step - loss: 1.0600 - accuracy: 0.6251 - val_loss: 2.0576 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.7942\n","Epoch 2: val_accuracy improved from 0.24359 to 0.25000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.6109 - accuracy: 0.7942 - val_loss: 5.3233 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.8222\n","Epoch 3: val_accuracy improved from 0.25000 to 0.42308, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.5226 - accuracy: 0.8222 - val_loss: 2.2304 - val_accuracy: 0.4231 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8396\n","Epoch 4: val_accuracy improved from 0.42308 to 0.75641, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4657 - accuracy: 0.8396 - val_loss: 0.7997 - val_accuracy: 0.7564 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.8536\n","Epoch 5: val_accuracy improved from 0.75641 to 0.76923, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.4219 - accuracy: 0.8536 - val_loss: 0.8848 - val_accuracy: 0.7692 - lr: 0.0010\n","Epoch 6/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3952 - accuracy: 0.8702\n","Epoch 6: val_accuracy improved from 0.76923 to 0.80769, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3947 - accuracy: 0.8704 - val_loss: 0.6749 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8800\n","Epoch 7: val_accuracy improved from 0.80769 to 0.83333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3577 - accuracy: 0.8800 - val_loss: 0.6242 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8873\n","Epoch 8: val_accuracy improved from 0.83333 to 0.85897, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 5s 40ms/step - loss: 0.3309 - accuracy: 0.8873 - val_loss: 0.7099 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.9009\n","Epoch 9: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3009 - accuracy: 0.9009 - val_loss: 0.6347 - val_accuracy: 0.8397 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9101\n","Epoch 10: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2703 - accuracy: 0.9101 - val_loss: 1.1415 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.9089\n","Epoch 11: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2572 - accuracy: 0.9089 - val_loss: 0.7798 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 12/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9221\n","Epoch 12: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2373 - accuracy: 0.9222 - val_loss: 0.8021 - val_accuracy: 0.8397 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9268\n","Epoch 13: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2143 - accuracy: 0.9268 - val_loss: 1.4705 - val_accuracy: 0.7244 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9321\n","Epoch 14: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1891 - accuracy: 0.9321 - val_loss: 1.1296 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9557\n","Epoch 15: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1274 - accuracy: 0.9557 - val_loss: 1.6914 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9670\n","Epoch 16: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1044 - accuracy: 0.9670 - val_loss: 0.9314 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 17/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9736\n","Epoch 17: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 1.4512 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9782\n","Epoch 18: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 1.1937 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9803\n","Epoch 19: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 1.4228 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9784\n","Epoch 20: val_accuracy did not improve from 0.85897\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0680 - accuracy: 0.9784 - val_loss: 1.3691 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","fold 7 / val_accuracy : 0.8590 / val_loss : 0.7099\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0657 - accuracy: 0.6264\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 48ms/step - loss: 1.0657 - accuracy: 0.6264 - val_loss: 2.6105 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7827\n","Epoch 2: val_accuracy improved from 0.24359 to 0.36538, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6241 - accuracy: 0.7827 - val_loss: 2.8736 - val_accuracy: 0.3654 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8180\n","Epoch 3: val_accuracy did not improve from 0.36538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.5201 - accuracy: 0.8180 - val_loss: 2.6232 - val_accuracy: 0.3654 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.8341\n","Epoch 4: val_accuracy improved from 0.36538 to 0.64103, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4691 - accuracy: 0.8341 - val_loss: 0.9293 - val_accuracy: 0.6410 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8554\n","Epoch 5: val_accuracy improved from 0.64103 to 0.77564, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4300 - accuracy: 0.8554 - val_loss: 0.7182 - val_accuracy: 0.7756 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8598\n","Epoch 6: val_accuracy did not improve from 0.77564\n","137/137 [==============================] - 5s 38ms/step - loss: 0.4047 - accuracy: 0.8598 - val_loss: 1.3522 - val_accuracy: 0.7628 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8798\n","Epoch 7: val_accuracy improved from 0.77564 to 0.79487, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3476 - accuracy: 0.8798 - val_loss: 0.8053 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 8/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8881\n","Epoch 8: val_accuracy did not improve from 0.79487\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3288 - accuracy: 0.8880 - val_loss: 1.5671 - val_accuracy: 0.7885 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8908\n","Epoch 9: val_accuracy improved from 0.79487 to 0.83333, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3076 - accuracy: 0.8908 - val_loss: 0.6553 - val_accuracy: 0.8333 - lr: 0.0010\n","Epoch 10/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2853 - accuracy: 0.8987\n","Epoch 10: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2849 - accuracy: 0.8988 - val_loss: 0.7464 - val_accuracy: 0.8269 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.9160\n","Epoch 11: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2585 - accuracy: 0.9160 - val_loss: 1.0554 - val_accuracy: 0.7821 - lr: 0.0010\n","Epoch 12/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9226\n","Epoch 12: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2401 - accuracy: 0.9222 - val_loss: 1.1946 - val_accuracy: 0.8269 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9252\n","Epoch 13: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2209 - accuracy: 0.9252 - val_loss: 0.7029 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 14/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1981 - accuracy: 0.9343\n","Epoch 14: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1989 - accuracy: 0.9339 - val_loss: 1.3581 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9399\n","Epoch 15: val_accuracy did not improve from 0.83333\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1686 - accuracy: 0.9399 - val_loss: 1.4654 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 16/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9598\n","Epoch 16: val_accuracy improved from 0.83333 to 0.85256, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.1156 - accuracy: 0.9596 - val_loss: 0.8217 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9727\n","Epoch 17: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 0.9430 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9743\n","Epoch 18: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0709 - accuracy: 0.9743 - val_loss: 0.9836 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 19/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9777\n","Epoch 19: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 1.0621 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 20/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9784\n","Epoch 20: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 1.2432 - val_accuracy: 0.8013 - lr: 5.0000e-04\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9805\n","Epoch 21: val_accuracy improved from 0.85256 to 0.87179, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 1.2724 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9832\n","Epoch 22: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 1.1460 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 23/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9846\n","Epoch 23: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0588 - accuracy: 0.9846 - val_loss: 1.3324 - val_accuracy: 0.7949 - lr: 5.0000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9858\n","Epoch 24: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0372 - accuracy: 0.9858 - val_loss: 1.8293 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9867\n","Epoch 25: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0399 - accuracy: 0.9867 - val_loss: 1.2242 - val_accuracy: 0.8333 - lr: 5.0000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9906\n","Epoch 26: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 2.1918 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 27/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9903\n","Epoch 27: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0460 - accuracy: 0.9904 - val_loss: 1.2254 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 28/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n","Epoch 28: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.1403 - val_accuracy: 0.8526 - lr: 2.5000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9961\n","Epoch 29: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 1.4619 - val_accuracy: 0.8654 - lr: 2.5000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9970\n","Epoch 30: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 1.4989 - val_accuracy: 0.8269 - lr: 2.5000e-04\n","Epoch 31/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n","Epoch 31: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.4842 - val_accuracy: 0.8590 - lr: 2.5000e-04\n","Epoch 32/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9961\n","Epoch 32: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.9150 - val_accuracy: 0.8333 - lr: 2.5000e-04\n","Epoch 33/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9956\n","Epoch 33: val_accuracy did not improve from 0.87179\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.4764 - val_accuracy: 0.8462 - lr: 2.5000e-04\n","fold 8 / val_accuracy : 0.8718 / val_loss : 1.2724\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.6122\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 46ms/step - loss: 1.0867 - accuracy: 0.6122 - val_loss: 2.0683 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.7809\n","Epoch 2: val_accuracy improved from 0.24359 to 0.27564, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6312 - accuracy: 0.7809 - val_loss: 2.8125 - val_accuracy: 0.2756 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.8118\n","Epoch 3: val_accuracy improved from 0.27564 to 0.33974, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5427 - accuracy: 0.8118 - val_loss: 3.5799 - val_accuracy: 0.3397 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.8281\n","Epoch 4: val_accuracy improved from 0.33974 to 0.70513, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4949 - accuracy: 0.8281 - val_loss: 1.0321 - val_accuracy: 0.7051 - lr: 0.0010\n","Epoch 5/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.4365 - accuracy: 0.8456\n","Epoch 5: val_accuracy improved from 0.70513 to 0.76282, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4373 - accuracy: 0.8456 - val_loss: 0.8991 - val_accuracy: 0.7628 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8651\n","Epoch 6: val_accuracy improved from 0.76282 to 0.86538, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4063 - accuracy: 0.8651 - val_loss: 0.4337 - val_accuracy: 0.8654 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8660\n","Epoch 7: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3812 - accuracy: 0.8660 - val_loss: 0.9271 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.8791\n","Epoch 8: val_accuracy did not improve from 0.86538\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3491 - accuracy: 0.8791 - val_loss: 0.6336 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 9/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.8883\n","Epoch 9: val_accuracy improved from 0.86538 to 0.89103, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3202 - accuracy: 0.8883 - val_loss: 0.6037 - val_accuracy: 0.8910 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.8970\n","Epoch 10: val_accuracy improved from 0.89103 to 0.91026, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.2892 - accuracy: 0.8970 - val_loss: 0.4108 - val_accuracy: 0.9103 - lr: 0.0010\n","Epoch 11/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.9062\n","Epoch 11: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2611 - accuracy: 0.9061 - val_loss: 0.4589 - val_accuracy: 0.8782 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9153\n","Epoch 12: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2371 - accuracy: 0.9153 - val_loss: 0.5450 - val_accuracy: 0.8397 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9167\n","Epoch 13: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2295 - accuracy: 0.9167 - val_loss: 0.6381 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9293\n","Epoch 14: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1941 - accuracy: 0.9293 - val_loss: 0.5659 - val_accuracy: 0.9038 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9383\n","Epoch 15: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1771 - accuracy: 0.9383 - val_loss: 0.9869 - val_accuracy: 0.8462 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9392\n","Epoch 16: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1800 - accuracy: 0.9392 - val_loss: 0.5857 - val_accuracy: 0.8846 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9665\n","Epoch 17: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0969 - accuracy: 0.9665 - val_loss: 0.6521 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9734\n","Epoch 18: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0724 - accuracy: 0.9734 - val_loss: 0.6864 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9761\n","Epoch 19: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0679 - accuracy: 0.9761 - val_loss: 0.7602 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9768\n","Epoch 20: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 0.8330 - val_accuracy: 0.8718 - lr: 5.0000e-04\n","Epoch 21/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9832\n","Epoch 21: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0565 - accuracy: 0.9832 - val_loss: 0.5972 - val_accuracy: 0.8590 - lr: 5.0000e-04\n","Epoch 22/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9818\n","Epoch 22: val_accuracy did not improve from 0.91026\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.7762 - val_accuracy: 0.8654 - lr: 5.0000e-04\n","fold 9 / val_accuracy : 0.9103 / val_loss : 0.4108\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.1899 - accuracy: 0.5741\n","Epoch 1: val_accuracy improved from -inf to 0.24359, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 45ms/step - loss: 1.1899 - accuracy: 0.5741 - val_loss: 1.5438 - val_accuracy: 0.2436 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7767\n","Epoch 2: val_accuracy improved from 0.24359 to 0.26282, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6595 - accuracy: 0.7767 - val_loss: 4.7005 - val_accuracy: 0.2628 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.8251\n","Epoch 3: val_accuracy improved from 0.26282 to 0.42308, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5279 - accuracy: 0.8251 - val_loss: 2.1151 - val_accuracy: 0.4231 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8387\n","Epoch 4: val_accuracy improved from 0.42308 to 0.53846, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4762 - accuracy: 0.8387 - val_loss: 1.9040 - val_accuracy: 0.5385 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8529\n","Epoch 5: val_accuracy improved from 0.53846 to 0.71154, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4315 - accuracy: 0.8529 - val_loss: 0.9802 - val_accuracy: 0.7115 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.8619\n","Epoch 6: val_accuracy did not improve from 0.71154\n","137/137 [==============================] - 5s 38ms/step - loss: 0.4165 - accuracy: 0.8619 - val_loss: 9.0693 - val_accuracy: 0.5641 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.8733\n","Epoch 7: val_accuracy improved from 0.71154 to 0.77564, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3722 - accuracy: 0.8733 - val_loss: 0.9315 - val_accuracy: 0.7756 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8791\n","Epoch 8: val_accuracy did not improve from 0.77564\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3519 - accuracy: 0.8791 - val_loss: 2.4075 - val_accuracy: 0.5641 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8839\n","Epoch 9: val_accuracy did not improve from 0.77564\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3627 - accuracy: 0.8839 - val_loss: 0.7892 - val_accuracy: 0.7436 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8993\n","Epoch 10: val_accuracy improved from 0.77564 to 0.80769, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3047 - accuracy: 0.8993 - val_loss: 0.9848 - val_accuracy: 0.8077 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9011\n","Epoch 11: val_accuracy did not improve from 0.80769\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2888 - accuracy: 0.9011 - val_loss: 0.8905 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 12/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9074\n","Epoch 12: val_accuracy did not improve from 0.80769\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2622 - accuracy: 0.9071 - val_loss: 1.8530 - val_accuracy: 0.6859 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9162\n","Epoch 13: val_accuracy did not improve from 0.80769\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2382 - accuracy: 0.9162 - val_loss: 1.6897 - val_accuracy: 0.7179 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9240\n","Epoch 14: val_accuracy did not improve from 0.80769\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2244 - accuracy: 0.9240 - val_loss: 1.2483 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9284\n","Epoch 15: val_accuracy did not improve from 0.80769\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2109 - accuracy: 0.9284 - val_loss: 2.7485 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9369\n","Epoch 16: val_accuracy improved from 0.80769 to 0.81410, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.1911 - accuracy: 0.9369 - val_loss: 0.9791 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9424\n","Epoch 17: val_accuracy did not improve from 0.81410\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1700 - accuracy: 0.9424 - val_loss: 1.0334 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9419\n","Epoch 18: val_accuracy did not improve from 0.81410\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1732 - accuracy: 0.9419 - val_loss: 1.0838 - val_accuracy: 0.8013 - lr: 0.0010\n","Epoch 19/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9458\n","Epoch 19: val_accuracy did not improve from 0.81410\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1666 - accuracy: 0.9454 - val_loss: 1.3143 - val_accuracy: 0.7115 - lr: 0.0010\n","Epoch 20/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9524\n","Epoch 20: val_accuracy improved from 0.81410 to 0.85256, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.1506 - accuracy: 0.9525 - val_loss: 0.9896 - val_accuracy: 0.8526 - lr: 0.0010\n","Epoch 21/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9555\n","Epoch 21: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1398 - accuracy: 0.9555 - val_loss: 1.0202 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9541\n","Epoch 22: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1287 - accuracy: 0.9541 - val_loss: 0.9154 - val_accuracy: 0.8141 - lr: 0.0010\n","Epoch 23/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9644\n","Epoch 23: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1133 - accuracy: 0.9644 - val_loss: 1.1911 - val_accuracy: 0.8526 - lr: 0.0010\n","Epoch 24/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9676\n","Epoch 24: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1225 - accuracy: 0.9674 - val_loss: 1.0661 - val_accuracy: 0.8205 - lr: 0.0010\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9651\n","Epoch 25: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0988 - accuracy: 0.9651 - val_loss: 1.8771 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 26/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9674\n","Epoch 26: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1072 - accuracy: 0.9672 - val_loss: 1.4119 - val_accuracy: 0.7949 - lr: 0.0010\n","Epoch 27/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9864\n","Epoch 27: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 1.2615 - val_accuracy: 0.8397 - lr: 5.0000e-04\n","Epoch 28/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9906\n","Epoch 28: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 1.2349 - val_accuracy: 0.8269 - lr: 5.0000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9906\n","Epoch 29: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 1.2925 - val_accuracy: 0.8462 - lr: 5.0000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9892\n","Epoch 30: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0452 - accuracy: 0.9892 - val_loss: 1.7227 - val_accuracy: 0.8141 - lr: 5.0000e-04\n","Epoch 31/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9936\n","Epoch 31: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 1.6440 - val_accuracy: 0.7949 - lr: 5.0000e-04\n","Epoch 32/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9936\n","Epoch 32: val_accuracy did not improve from 0.85256\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 1.5841 - val_accuracy: 0.8526 - lr: 5.0000e-04\n","fold 10 / val_accuracy : 0.8526 / val_loss : 0.9896\n","Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.1348 - accuracy: 0.5990\n","Epoch 1: val_accuracy improved from -inf to 0.25806, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 13s 47ms/step - loss: 1.1349 - accuracy: 0.5991 - val_loss: 1.4754 - val_accuracy: 0.2581 - lr: 0.0010\n","Epoch 2/60\n","137/137 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7674\n","Epoch 2: val_accuracy improved from 0.25806 to 0.29032, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6595 - accuracy: 0.7674 - val_loss: 2.4471 - val_accuracy: 0.2903 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.8048\n","Epoch 3: val_accuracy improved from 0.29032 to 0.34194, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5523 - accuracy: 0.8048 - val_loss: 3.0455 - val_accuracy: 0.3419 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.8362\n","Epoch 4: val_accuracy improved from 0.34194 to 0.75484, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4894 - accuracy: 0.8362 - val_loss: 0.6333 - val_accuracy: 0.7548 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.8516\n","Epoch 5: val_accuracy improved from 0.75484 to 0.83871, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4392 - accuracy: 0.8516 - val_loss: 0.4259 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 6/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8601\n","Epoch 6: val_accuracy improved from 0.83871 to 0.84516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3895 - accuracy: 0.8599 - val_loss: 0.4534 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8725\n","Epoch 7: val_accuracy improved from 0.84516 to 0.87742, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3623 - accuracy: 0.8725 - val_loss: 0.4329 - val_accuracy: 0.8774 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8888\n","Epoch 8: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3285 - accuracy: 0.8888 - val_loss: 0.8261 - val_accuracy: 0.7742 - lr: 0.0010\n","Epoch 9/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8968\n","Epoch 9: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3098 - accuracy: 0.8970 - val_loss: 0.6673 - val_accuracy: 0.7806 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8929\n","Epoch 10: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3064 - accuracy: 0.8929 - val_loss: 0.5679 - val_accuracy: 0.8258 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9087\n","Epoch 11: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2648 - accuracy: 0.9087 - val_loss: 0.6214 - val_accuracy: 0.8645 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9124\n","Epoch 12: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2564 - accuracy: 0.9124 - val_loss: 0.6003 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 13/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9159\n","Epoch 13: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2270 - accuracy: 0.9156 - val_loss: 2.4975 - val_accuracy: 0.6839 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9431\n","Epoch 14: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1621 - accuracy: 0.9431 - val_loss: 0.5407 - val_accuracy: 0.8645 - lr: 5.0000e-04\n","Epoch 15/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9605\n","Epoch 15: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1217 - accuracy: 0.9601 - val_loss: 0.6790 - val_accuracy: 0.8516 - lr: 5.0000e-04\n","Epoch 16/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9621\n","Epoch 16: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1106 - accuracy: 0.9622 - val_loss: 0.8278 - val_accuracy: 0.8645 - lr: 5.0000e-04\n","Epoch 17/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9720\n","Epoch 17: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.7919 - val_accuracy: 0.8323 - lr: 5.0000e-04\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9731\n","Epoch 18: val_accuracy improved from 0.87742 to 0.88387, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.0901 - accuracy: 0.9732 - val_loss: 0.6983 - val_accuracy: 0.8839 - lr: 5.0000e-04\n","Epoch 19/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9777\n","Epoch 19: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.9682 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9787\n","Epoch 20: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0742 - accuracy: 0.9787 - val_loss: 0.7843 - val_accuracy: 0.8645 - lr: 5.0000e-04\n","Epoch 21/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9770\n","Epoch 21: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0673 - accuracy: 0.9768 - val_loss: 0.9114 - val_accuracy: 0.8065 - lr: 5.0000e-04\n","Epoch 22/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9803\n","Epoch 22: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0675 - accuracy: 0.9803 - val_loss: 1.0023 - val_accuracy: 0.8452 - lr: 5.0000e-04\n","Epoch 23/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9821\n","Epoch 23: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 1.1865 - val_accuracy: 0.8323 - lr: 5.0000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9837\n","Epoch 24: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 1.2417 - val_accuracy: 0.8129 - lr: 5.0000e-04\n","Epoch 25/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9906\n","Epoch 25: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.9796 - val_accuracy: 0.8516 - lr: 2.5000e-04\n","Epoch 26/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9938\n","Epoch 26: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 1.1576 - val_accuracy: 0.8387 - lr: 2.5000e-04\n","Epoch 27/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9949\n","Epoch 27: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 1.1200 - val_accuracy: 0.8258 - lr: 2.5000e-04\n","Epoch 28/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9954\n","Epoch 28: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 1.3067 - val_accuracy: 0.8516 - lr: 2.5000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9947\n","Epoch 29: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 1.0811 - val_accuracy: 0.8581 - lr: 2.5000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n","Epoch 30: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 1.2481 - val_accuracy: 0.8516 - lr: 2.5000e-04\n","fold 11 / val_accuracy : 0.8839 / val_loss : 0.6983\n","Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.0402 - accuracy: 0.6206\n","Epoch 1: val_accuracy improved from -inf to 0.24516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 13s 47ms/step - loss: 1.0395 - accuracy: 0.6209 - val_loss: 1.8777 - val_accuracy: 0.2452 - lr: 0.0010\n","Epoch 2/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.6138 - accuracy: 0.7824\n","Epoch 2: val_accuracy improved from 0.24516 to 0.25806, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6138 - accuracy: 0.7823 - val_loss: 3.1006 - val_accuracy: 0.2581 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8076\n","Epoch 3: val_accuracy improved from 0.25806 to 0.36774, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5509 - accuracy: 0.8076 - val_loss: 2.3339 - val_accuracy: 0.3677 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8408\n","Epoch 4: val_accuracy improved from 0.36774 to 0.60000, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4674 - accuracy: 0.8408 - val_loss: 1.7590 - val_accuracy: 0.6000 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8557\n","Epoch 5: val_accuracy improved from 0.60000 to 0.73548, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4347 - accuracy: 0.8557 - val_loss: 0.6762 - val_accuracy: 0.7355 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8642\n","Epoch 6: val_accuracy improved from 0.73548 to 0.76129, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3908 - accuracy: 0.8642 - val_loss: 1.0514 - val_accuracy: 0.7613 - lr: 0.0010\n","Epoch 7/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.8761\n","Epoch 7: val_accuracy did not improve from 0.76129\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3561 - accuracy: 0.8759 - val_loss: 0.9079 - val_accuracy: 0.7226 - lr: 0.0010\n","Epoch 8/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3484 - accuracy: 0.8814\n","Epoch 8: val_accuracy improved from 0.76129 to 0.86452, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3478 - accuracy: 0.8817 - val_loss: 0.4453 - val_accuracy: 0.8645 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8917\n","Epoch 9: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3030 - accuracy: 0.8917 - val_loss: 0.7408 - val_accuracy: 0.7935 - lr: 0.0010\n","Epoch 10/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.8952\n","Epoch 10: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2992 - accuracy: 0.8950 - val_loss: 0.5793 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 11/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9072\n","Epoch 11: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2593 - accuracy: 0.9073 - val_loss: 0.4542 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.9112\n","Epoch 12: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2507 - accuracy: 0.9112 - val_loss: 0.7283 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 13/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9196\n","Epoch 13: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2234 - accuracy: 0.9193 - val_loss: 1.1107 - val_accuracy: 0.7677 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9280\n","Epoch 14: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2175 - accuracy: 0.9280 - val_loss: 0.4061 - val_accuracy: 0.8645 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9518\n","Epoch 15: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1430 - accuracy: 0.9518 - val_loss: 0.5805 - val_accuracy: 0.8516 - lr: 5.0000e-04\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9596\n","Epoch 16: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1249 - accuracy: 0.9596 - val_loss: 0.8059 - val_accuracy: 0.8194 - lr: 5.0000e-04\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9647\n","Epoch 17: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1105 - accuracy: 0.9647 - val_loss: 0.6784 - val_accuracy: 0.8258 - lr: 5.0000e-04\n","Epoch 18/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9741\n","Epoch 18: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0909 - accuracy: 0.9741 - val_loss: 0.7023 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 19/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9743\n","Epoch 19: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 0.6635 - val_accuracy: 0.8452 - lr: 5.0000e-04\n","Epoch 20/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9794\n","Epoch 20: val_accuracy did not improve from 0.86452\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0696 - accuracy: 0.9794 - val_loss: 0.7609 - val_accuracy: 0.8387 - lr: 5.0000e-04\n","fold 12 / val_accuracy : 0.8645 / val_loss : 0.4453\n","Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.1072 - accuracy: 0.6137\n","Epoch 1: val_accuracy improved from -inf to 0.28387, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 46ms/step - loss: 1.1068 - accuracy: 0.6135 - val_loss: 1.7697 - val_accuracy: 0.2839 - lr: 0.0010\n","Epoch 2/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.6204 - accuracy: 0.7806\n","Epoch 2: val_accuracy improved from 0.28387 to 0.39355, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6199 - accuracy: 0.7810 - val_loss: 2.4972 - val_accuracy: 0.3935 - lr: 0.0010\n","Epoch 3/60\n","137/137 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.8239\n","Epoch 3: val_accuracy improved from 0.39355 to 0.52903, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5112 - accuracy: 0.8239 - val_loss: 1.0756 - val_accuracy: 0.5290 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.8360\n","Epoch 4: val_accuracy improved from 0.52903 to 0.81290, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4698 - accuracy: 0.8360 - val_loss: 0.7053 - val_accuracy: 0.8129 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.8491\n","Epoch 5: val_accuracy did not improve from 0.81290\n","137/137 [==============================] - 5s 38ms/step - loss: 0.4218 - accuracy: 0.8491 - val_loss: 0.7802 - val_accuracy: 0.7226 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8606\n","Epoch 6: val_accuracy did not improve from 0.81290\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3918 - accuracy: 0.8606 - val_loss: 3.3333 - val_accuracy: 0.5355 - lr: 0.0010\n","Epoch 7/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8697\n","Epoch 7: val_accuracy did not improve from 0.81290\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3785 - accuracy: 0.8700 - val_loss: 0.7870 - val_accuracy: 0.7742 - lr: 0.0010\n","Epoch 8/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8842\n","Epoch 8: val_accuracy improved from 0.81290 to 0.87742, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 40ms/step - loss: 0.3247 - accuracy: 0.8842 - val_loss: 0.4050 - val_accuracy: 0.8774 - lr: 0.0010\n","Epoch 9/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.8908\n","Epoch 9: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 40ms/step - loss: 0.2961 - accuracy: 0.8908 - val_loss: 0.4812 - val_accuracy: 0.8323 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9078\n","Epoch 10: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2662 - accuracy: 0.9078 - val_loss: 0.4777 - val_accuracy: 0.8516 - lr: 0.0010\n","Epoch 11/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9062\n","Epoch 11: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2570 - accuracy: 0.9053 - val_loss: 0.7452 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 12/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.9152\n","Epoch 12: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2385 - accuracy: 0.9151 - val_loss: 0.6304 - val_accuracy: 0.8258 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9259\n","Epoch 13: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2201 - accuracy: 0.9259 - val_loss: 0.5371 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.9333\n","Epoch 14: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2091 - accuracy: 0.9333 - val_loss: 1.1575 - val_accuracy: 0.7032 - lr: 0.0010\n","Epoch 15/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9529\n","Epoch 15: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1308 - accuracy: 0.9530 - val_loss: 0.6082 - val_accuracy: 0.8387 - lr: 5.0000e-04\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9677\n","Epoch 16: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0888 - accuracy: 0.9677 - val_loss: 0.5550 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 17/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9708\n","Epoch 17: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0832 - accuracy: 0.9709 - val_loss: 0.7485 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9736\n","Epoch 18: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0782 - accuracy: 0.9734 - val_loss: 0.8746 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9766\n","Epoch 19: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0670 - accuracy: 0.9766 - val_loss: 0.7418 - val_accuracy: 0.8194 - lr: 5.0000e-04\n","Epoch 20/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9784\n","Epoch 20: val_accuracy did not improve from 0.87742\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 1.1646 - val_accuracy: 0.7871 - lr: 5.0000e-04\n","fold 13 / val_accuracy : 0.8774 / val_loss : 0.4050\n","Epoch 1/60\n","137/137 [==============================] - ETA: 0s - loss: 1.0714 - accuracy: 0.6273\n","Epoch 1: val_accuracy improved from -inf to 0.24516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 14s 47ms/step - loss: 1.0714 - accuracy: 0.6273 - val_loss: 3.1442 - val_accuracy: 0.2452 - lr: 0.0010\n","Epoch 2/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.6070 - accuracy: 0.7870\n","Epoch 2: val_accuracy improved from 0.24516 to 0.32903, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.6072 - accuracy: 0.7867 - val_loss: 1.8971 - val_accuracy: 0.3290 - lr: 0.0010\n","Epoch 3/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.8164\n","Epoch 3: val_accuracy did not improve from 0.32903\n","137/137 [==============================] - 5s 39ms/step - loss: 0.5255 - accuracy: 0.8167 - val_loss: 3.1428 - val_accuracy: 0.3226 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8344\n","Epoch 4: val_accuracy improved from 0.32903 to 0.67742, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4713 - accuracy: 0.8344 - val_loss: 1.2112 - val_accuracy: 0.6774 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.8534\n","Epoch 5: val_accuracy improved from 0.67742 to 0.84516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4332 - accuracy: 0.8534 - val_loss: 0.6045 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8564\n","Epoch 6: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.4084 - accuracy: 0.8564 - val_loss: 1.6799 - val_accuracy: 0.7032 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.8745\n","Epoch 7: val_accuracy improved from 0.84516 to 0.88387, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3614 - accuracy: 0.8745 - val_loss: 0.4407 - val_accuracy: 0.8839 - lr: 0.0010\n","Epoch 8/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8867\n","Epoch 8: val_accuracy did not improve from 0.88387\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3423 - accuracy: 0.8867 - val_loss: 0.5461 - val_accuracy: 0.8710 - lr: 0.0010\n","Epoch 9/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9003\n","Epoch 9: val_accuracy improved from 0.88387 to 0.89677, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 42ms/step - loss: 0.2904 - accuracy: 0.9002 - val_loss: 0.3343 - val_accuracy: 0.8968 - lr: 0.0010\n","Epoch 10/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.9016\n","Epoch 10: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2682 - accuracy: 0.9016 - val_loss: 0.4876 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 11/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9120\n","Epoch 11: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2475 - accuracy: 0.9117 - val_loss: 0.5117 - val_accuracy: 0.8710 - lr: 0.0010\n","Epoch 12/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9202\n","Epoch 12: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2379 - accuracy: 0.9202 - val_loss: 0.3435 - val_accuracy: 0.8903 - lr: 0.0010\n","Epoch 13/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9269\n","Epoch 13: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2033 - accuracy: 0.9266 - val_loss: 1.1038 - val_accuracy: 0.8129 - lr: 0.0010\n","Epoch 14/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9360\n","Epoch 14: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1802 - accuracy: 0.9360 - val_loss: 0.4763 - val_accuracy: 0.8839 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9383\n","Epoch 15: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1727 - accuracy: 0.9383 - val_loss: 0.6815 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9661\n","Epoch 16: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.1036 - accuracy: 0.9661 - val_loss: 0.4535 - val_accuracy: 0.8839 - lr: 5.0000e-04\n","Epoch 17/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9731\n","Epoch 17: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 0.5953 - val_accuracy: 0.8968 - lr: 5.0000e-04\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9740\n","Epoch 18: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0758 - accuracy: 0.9741 - val_loss: 0.5813 - val_accuracy: 0.8903 - lr: 5.0000e-04\n","Epoch 19/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9805\n","Epoch 19: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.6434 - val_accuracy: 0.8645 - lr: 5.0000e-04\n","Epoch 20/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9809\n","Epoch 20: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0587 - accuracy: 0.9807 - val_loss: 0.9710 - val_accuracy: 0.8774 - lr: 5.0000e-04\n","Epoch 21/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9784\n","Epoch 21: val_accuracy did not improve from 0.89677\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0596 - accuracy: 0.9782 - val_loss: 0.7999 - val_accuracy: 0.8645 - lr: 5.0000e-04\n","fold 14 / val_accuracy : 0.8968 / val_loss : 0.3343\n","Epoch 1/60\n","136/137 [============================>.] - ETA: 0s - loss: 1.1150 - accuracy: 0.6140\n","Epoch 1: val_accuracy improved from -inf to 0.24516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 13s 47ms/step - loss: 1.1137 - accuracy: 0.6147 - val_loss: 1.6522 - val_accuracy: 0.2452 - lr: 0.0010\n","Epoch 2/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.6318 - accuracy: 0.7852\n","Epoch 2: val_accuracy did not improve from 0.24516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.6322 - accuracy: 0.7851 - val_loss: 3.1588 - val_accuracy: 0.2452 - lr: 0.0010\n","Epoch 3/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8176\n","Epoch 3: val_accuracy improved from 0.24516 to 0.37419, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.5296 - accuracy: 0.8177 - val_loss: 2.5211 - val_accuracy: 0.3742 - lr: 0.0010\n","Epoch 4/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.8436\n","Epoch 4: val_accuracy improved from 0.37419 to 0.79355, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.4664 - accuracy: 0.8436 - val_loss: 0.6330 - val_accuracy: 0.7935 - lr: 0.0010\n","Epoch 5/60\n","137/137 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8484\n","Epoch 5: val_accuracy did not improve from 0.79355\n","137/137 [==============================] - 5s 39ms/step - loss: 0.4416 - accuracy: 0.8484 - val_loss: 0.9633 - val_accuracy: 0.7226 - lr: 0.0010\n","Epoch 6/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8679\n","Epoch 6: val_accuracy did not improve from 0.79355\n","137/137 [==============================] - 5s 38ms/step - loss: 0.3945 - accuracy: 0.8679 - val_loss: 0.6672 - val_accuracy: 0.7742 - lr: 0.0010\n","Epoch 7/60\n","137/137 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8693\n","Epoch 7: val_accuracy improved from 0.79355 to 0.83871, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3792 - accuracy: 0.8693 - val_loss: 0.5606 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 8/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8872\n","Epoch 8: val_accuracy did not improve from 0.83871\n","137/137 [==============================] - 5s 39ms/step - loss: 0.3354 - accuracy: 0.8872 - val_loss: 1.3641 - val_accuracy: 0.7484 - lr: 0.0010\n","Epoch 9/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8840\n","Epoch 9: val_accuracy improved from 0.83871 to 0.84516, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.3333 - accuracy: 0.8839 - val_loss: 0.6713 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 10/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8968\n","Epoch 10: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 38ms/step - loss: 0.2994 - accuracy: 0.8970 - val_loss: 0.7186 - val_accuracy: 0.7935 - lr: 0.0010\n","Epoch 11/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.9089\n","Epoch 11: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2592 - accuracy: 0.9089 - val_loss: 0.7848 - val_accuracy: 0.8387 - lr: 0.0010\n","Epoch 12/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.9161\n","Epoch 12: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2528 - accuracy: 0.9161 - val_loss: 0.5330 - val_accuracy: 0.8452 - lr: 0.0010\n","Epoch 13/60\n","137/137 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9158\n","Epoch 13: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2310 - accuracy: 0.9158 - val_loss: 0.8283 - val_accuracy: 0.8065 - lr: 0.0010\n","Epoch 14/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9260\n","Epoch 14: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 39ms/step - loss: 0.2100 - accuracy: 0.9257 - val_loss: 0.6450 - val_accuracy: 0.8194 - lr: 0.0010\n","Epoch 15/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9303\n","Epoch 15: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1907 - accuracy: 0.9303 - val_loss: 0.8223 - val_accuracy: 0.8258 - lr: 0.0010\n","Epoch 16/60\n","137/137 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9573\n","Epoch 16: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 38ms/step - loss: 0.1044 - accuracy: 0.9573 - val_loss: 0.6363 - val_accuracy: 0.8258 - lr: 5.0000e-04\n","Epoch 17/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9688\n","Epoch 17: val_accuracy did not improve from 0.84516\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 1.0454 - val_accuracy: 0.8194 - lr: 5.0000e-04\n","Epoch 18/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9731\n","Epoch 18: val_accuracy improved from 0.84516 to 0.85806, saving model to CNN-checkpoint.h5\n","137/137 [==============================] - 6s 41ms/step - loss: 0.0692 - accuracy: 0.9732 - val_loss: 1.1437 - val_accuracy: 0.8581 - lr: 5.0000e-04\n","Epoch 19/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9800\n","Epoch 19: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.9439 - val_accuracy: 0.8387 - lr: 5.0000e-04\n","Epoch 20/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9798\n","Epoch 20: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 1.8525 - val_accuracy: 0.7613 - lr: 5.0000e-04\n","Epoch 21/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9821\n","Epoch 21: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0556 - accuracy: 0.9821 - val_loss: 1.3221 - val_accuracy: 0.8323 - lr: 5.0000e-04\n","Epoch 22/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9846\n","Epoch 22: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0463 - accuracy: 0.9846 - val_loss: 1.3514 - val_accuracy: 0.8516 - lr: 5.0000e-04\n","Epoch 23/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9828\n","Epoch 23: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0475 - accuracy: 0.9828 - val_loss: 1.3676 - val_accuracy: 0.8323 - lr: 5.0000e-04\n","Epoch 24/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9823\n","Epoch 24: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 1.1622 - val_accuracy: 0.8452 - lr: 5.0000e-04\n","Epoch 25/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9922\n","Epoch 25: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 1.1754 - val_accuracy: 0.8452 - lr: 2.5000e-04\n","Epoch 26/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9949\n","Epoch 26: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 1.1781 - val_accuracy: 0.8387 - lr: 2.5000e-04\n","Epoch 27/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9954\n","Epoch 27: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 1.4241 - val_accuracy: 0.8129 - lr: 2.5000e-04\n","Epoch 28/60\n","136/137 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9963\n","Epoch 28: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.3092 - val_accuracy: 0.8452 - lr: 2.5000e-04\n","Epoch 29/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9956\n","Epoch 29: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 38ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.6135 - val_accuracy: 0.8323 - lr: 2.5000e-04\n","Epoch 30/60\n","137/137 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9963\n","Epoch 30: val_accuracy did not improve from 0.85806\n","137/137 [==============================] - 5s 39ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.6289 - val_accuracy: 0.8323 - lr: 2.5000e-04\n","fold 15 / val_accuracy : 0.8581 / val_loss : 1.1437\n"]}]},{"cell_type":"code","source":["pred_proba = cnn_pred[0]\n","pred_proba = np.array(pred_proba)\n","print(pred_proba[0])\n","\n","for x in range(1, 15):\n","    pred_proba += cnn_pred[x]\n","    print(cnn_pred[x][0])\n","\n","pred_class = []\n","\n","for i in pred_proba:\n","    pred = np.argmax(i)\n","    pred_class.append(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Gdq4wvCvUrV","executionInfo":{"status":"ok","timestamp":1647595287798,"user_tz":-540,"elapsed":441,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"926c3cc2-5fd2-46d2-a3f9-c51dfdfdf168"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0000000e+00 3.8862729e-11 1.2182455e-09 2.4991947e-10]\n","[9.9999988e-01 1.3635090e-09 3.2203697e-08 5.4746806e-08]\n","[9.9999964e-01 2.9515110e-07 1.5564758e-08 1.1760403e-07]\n","[9.9999917e-01 1.1761632e-07 7.0937398e-07 1.0406036e-09]\n","[9.9999082e-01 4.4541046e-08 3.3078511e-08 9.1409993e-06]\n","[1.0000000e+00 4.1992247e-12 3.5888102e-11 2.7059099e-10]\n","[9.9998295e-01 1.1434765e-06 1.4482791e-05 1.3308984e-06]\n","[9.9999738e-01 4.5476309e-10 2.6673918e-06 1.0789051e-10]\n","[9.9863619e-01 1.2927447e-05 1.3496318e-03 1.1349587e-06]\n","[1.0000000e+00 9.5521342e-09 2.2710593e-10 2.3098019e-08]\n","[1.0000000e+00 5.6799578e-12 4.6634937e-14 4.3602402e-10]\n","[9.9997103e-01 7.1018655e-07 2.7927375e-05 2.6690222e-07]\n","[9.9996877e-01 4.0141013e-06 2.7032042e-05 1.2837310e-07]\n","[9.9529159e-01 5.2525662e-04 3.8719545e-03 3.1127414e-04]\n","[9.9999988e-01 4.5063347e-10 5.4875184e-08 2.0691900e-08]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","sample_submission = pd.read_csv(PATH+\"sample_submission.csv\")\n","\n","sample_submission.target = pred_class\n","sample_submission.to_csv(PATH+\"submit_짱짱걸1.csv\",index=False)"],"metadata":{"id":"D5adI-devgWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"FYLQ0qlJvh3T","executionInfo":{"status":"ok","timestamp":1647591263633,"user_tz":-540,"elapsed":7,"user":{"displayName":"‍엄지연(대학원생-비즈니스IT전공)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07422877967370686583"}},"outputId":"450e4355-564f-45d6-a6df-88bbbc665607"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  target\n","0   1       0\n","1   2       0\n","2   3       1\n","3   4       3\n","4   5       2"],"text/html":["\n","  <div id=\"df-1de48780-ef57-4b9a-853f-7925588466a4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1de48780-ef57-4b9a-853f-7925588466a4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1de48780-ef57-4b9a-853f-7925588466a4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1de48780-ef57-4b9a-853f-7925588466a4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":[""],"metadata":{"id":"C3ktUc4hvkH6"},"execution_count":null,"outputs":[]}]}